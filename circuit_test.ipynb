{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_253155/621318041.py\", line 6, in <module>\n",
      "    from nnsight import LanguageModel\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/nnsight/__init__.py\", line 6, in <module>\n",
      "    import torch\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/yiran/miniconda3/envs/circuit_main/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from dictionary_learning import AutoEncoder\n",
    "from circuit import get_circuit\n",
    "from circuit_plotting import plot_circuit\n",
    "from activation_utils import SparseAct\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "\n",
    "DEBUGGING = False\n",
    "if DEBUGGING:\n",
    "    tracer_kwargs = {'validate' : True, 'scan' : True}\n",
    "else:\n",
    "    tracer_kwargs = {'validate' : False, 'scan' : False}\n",
    "\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n"
     ]
    }
   ],
   "source": [
    "model_cache_dir = \"/media/data/yiran/hf_cache/hub\"\n",
    "data_cache_dir = \"/media/data/yiran/hf_cache/datasets\"\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', cache_dir=model_cache_dir, device_map=DEVICE, dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.gpt_neox.embed_in\n",
    "attns = [layer.attention for layer in model.gpt_neox.layers]\n",
    "mlps = [layer.mlp for layer in model.gpt_neox.layers]\n",
    "resids = [layer for layer in model.gpt_neox.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_submods = [embed] + [submod for layer_submods in zip(mlps, attns, resids) for submod in layer_submods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Embedding(50304, 512),\n",
       " GPTNeoXMLP(\n",
       "   (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (act): GELUActivation()\n",
       " ),\n",
       " GPTNeoXSdpaAttention(\n",
       "   (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "   (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " GPTNeoXLayer(\n",
       "   (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (attention): GPTNeoXSdpaAttention(\n",
       "     (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "     (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (mlp): GPTNeoXMLP(\n",
       "     (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (act): GELUActivation()\n",
       "   )\n",
       " ),\n",
       " GPTNeoXMLP(\n",
       "   (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (act): GELUActivation()\n",
       " ),\n",
       " GPTNeoXSdpaAttention(\n",
       "   (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "   (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " GPTNeoXLayer(\n",
       "   (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (attention): GPTNeoXSdpaAttention(\n",
       "     (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "     (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (mlp): GPTNeoXMLP(\n",
       "     (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (act): GELUActivation()\n",
       "   )\n",
       " ),\n",
       " GPTNeoXMLP(\n",
       "   (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (act): GELUActivation()\n",
       " ),\n",
       " GPTNeoXSdpaAttention(\n",
       "   (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "   (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " GPTNeoXLayer(\n",
       "   (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (attention): GPTNeoXSdpaAttention(\n",
       "     (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "     (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (mlp): GPTNeoXMLP(\n",
       "     (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (act): GELUActivation()\n",
       "   )\n",
       " ),\n",
       " GPTNeoXMLP(\n",
       "   (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (act): GELUActivation()\n",
       " ),\n",
       " GPTNeoXSdpaAttention(\n",
       "   (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "   (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " GPTNeoXLayer(\n",
       "   (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (attention): GPTNeoXSdpaAttention(\n",
       "     (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "     (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (mlp): GPTNeoXMLP(\n",
       "     (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (act): GELUActivation()\n",
       "   )\n",
       " ),\n",
       " GPTNeoXMLP(\n",
       "   (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (act): GELUActivation()\n",
       " ),\n",
       " GPTNeoXSdpaAttention(\n",
       "   (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "   (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " GPTNeoXLayer(\n",
       "   (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (attention): GPTNeoXSdpaAttention(\n",
       "     (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "     (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (mlp): GPTNeoXMLP(\n",
       "     (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (act): GELUActivation()\n",
       "   )\n",
       " ),\n",
       " GPTNeoXMLP(\n",
       "   (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (act): GELUActivation()\n",
       " ),\n",
       " GPTNeoXSdpaAttention(\n",
       "   (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "   (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " GPTNeoXLayer(\n",
       "   (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (attention): GPTNeoXSdpaAttention(\n",
       "     (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "     (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (mlp): GPTNeoXMLP(\n",
       "     (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (act): GELUActivation()\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_submods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Size'>\n",
      "<class 'torch.Size'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'torch.Size'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'torch.Size'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'torch.Size'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'torch.Size'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'torch.Size'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "is_tuple = {}\n",
    "with model.trace(\"_\"):\n",
    "    for submodule in all_submods:\n",
    "        print(type(submodule.output.shape))\n",
    "        is_tuple[submodule] = type(submodule.output.shape) == tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuit_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
